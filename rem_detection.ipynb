{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import mne\n",
    "import yasa\n",
    "import math\n",
    "import matplotlib as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "participants = ['BPM0004','BPM0005','BPM0006','BPM0007','BPM0008','BPM0009','BPM0010','BPM0011','BPM0012','BPM0013','BPM0014','BPM0015','BPM0016','BPM0017','BPM0018','BPM0019','BPM0020','BPM0021','BPM0022','BPM0023','BPM0024','BPM0025','BPM0026','BPM0027','BPM0028','BPM0029','BPM0032','BPM0033','BPM0034','BPM0035','BPM0036','BPM0038','BPM0040','BPM0041','BPM0042','BPM0044','BPM0045','BPM0046','BPM0047','BPM0048','BPM0049','BPM0050','BPM0051','BPM0052','BPM0053','BPM0054','BPM0055','BPM0056','BPM0057','BPM0058','BPM0059','BPM0060','BPM0061','BPM0062','BPM0063','BPM0064','BPM0065','BPM0066','BPM0067','BPM0068','BPM0069','BPM0070','BPM0071','BPM0072','BPM0073','BPM0074','BPM0075','BPM0076','BPM0077','BPM0078','BPM0079','BPM0080','BPM0081','BPM0082','BPM0083','BPM0084','BPM0085','BPM0088','BPM0089','BPM0090','BPM0091','BPM0092','BPM0093','BPM0094','BPM0095','BPM0096','BPM0097','BPM0098','BPM0099','BPM0100','BPM0101','BPM0102','BPM0103','BPM0104','BPM0105','BPM0106','BPM0107','BPM0108','BPM0109','BPM0110','BPM0111','BPM0112','BPM0113','BPM0114','BPM0115','BPM0117','BPM0118','BPM0119','BPM0120','BPM0121','BPM0122','BPM0123','BPM0124','BPM0125','BPM0126','BPM0127','BPM0128','BPM0129','BPM0130','BPM0131','BPM0132','BPM0133','BPM0134','BPM0135','BPM0136','BPM0137','BPM0138','BPM0139','BPM0141','BPM0142','BPM0143','BPM0148','BPM0149','BPM0153','BPM0154','BPM0155','BPM0158','BPM0161','BPM0162','BPM0165','BPM0167','BPM0169','BPM0171','BPM0175','BPM0176','BPM0177','BPM0178','BPM0179','BPM0181','BPM0182','BPM0183','BPM0185','BPM0186','BPM0188','BPM0192','BPM0193','BPM0194','BPM0195','BPM0196','BPM0197','BPM0198','BPM0202','BPM0205','BPM0208','BPM0209','BPM0210','BPM0211','BPM0212','BPM0213','BPM0214','BPM0215','BPM0216','BPM0220','BPM0221','BPM0224','BPM0225','BPM0226','BPM0227','BPM0228''BPM0229','BPM0230','BPM0231','BPM0233','BPM0234','BPM0235','BPM0236','BPM0237','BPM0238','BPM0239','BPM0240','BPM0241','BPM0242','BPM0243','BPM0244','BPM0245','BPM0246','BPM0247','BPM0248','BPM0249','BPM0250','BPM0251']\n",
    "# Select window size\n",
    "window = 2\n",
    "\n",
    "# Initialize large matrices or lists to store results for all participants\n",
    "all_results_filt = []\n",
    "wrong_amplitude_channels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the REM detection function that creates the matrix content\n",
    "def detect_rems(raw_data, roc_channel, loc_channel, hypno, artefacts):\n",
    "    \"\"\"Detect REMs using YASA's REM detection function.\n",
    "\n",
    "    Args:\n",
    "        raw_data: Raw data object from MNE.\n",
    "        roc_channel: Name of the ROC channel.\n",
    "        loc_channel: Name of the LOC channel.\n",
    "\n",
    "    Returns:\n",
    "        REM detection results.\n",
    "    \"\"\"\n",
    "    # Get the sampling frequency\n",
    "    sf = raw_data.info['sfreq']\n",
    "\n",
    "    # Given your sampling frequency is 512 Hz, each 2-second window will have 512 * 2 = 1024 samples.\n",
    "    window_size = window * sf  # 2-second windows\n",
    "    num_windows = raw_data.n_times // window_size\n",
    "\n",
    "    # Placeholder for results\n",
    "    rem_window_results = []\n",
    "\n",
    "    # Create copies of the raw data for each channel\n",
    "    raw_copy_roc = raw_data.copy().pick([roc_channel])\n",
    "    raw_copy_loc = raw_data.copy().pick([loc_channel])\n",
    "\n",
    "    # Get the data for each channel\n",
    "    #ROC_data = raw_copy_roc.get_data(units=\"mV\")[0]  # Select first (and only) channel's data\n",
    "    #LOC_data = raw_copy_loc.get_data(units=\"mV\")[0]  # Select first (and only) channel's data\n",
    "    ROC_data = raw_copy_roc.get_data(units=\"uV\")[0]  # Select first (and only) channel's data\n",
    "    LOC_data = raw_copy_loc.get_data(units=\"uV\")[0]  # Select first (and only) channel's data\n",
    "\n",
    "    # After scaling, try running rem_detect again\n",
    "    rem = yasa.rem_detect(ROC_data, LOC_data, sf=sf, hypno=None)\n",
    "\n",
    "    # If no REM events are detected, try with millivolts\n",
    "    if rem is None or rem.summary().empty:\n",
    "        # Need to skip these channels\n",
    "        ROC_data = raw_copy_roc.get_data(units=\"mV\")[0]  # Select first (and only) channel's data\n",
    "        LOC_data = raw_copy_loc.get_data(units=\"mV\")[0]  # Select first (and only) channel's data\n",
    "        wrong_amplitude_channels.append(participant)\n",
    "\n",
    "        rem = yasa.rem_detect(ROC_data, LOC_data, sf=sf, hypno=None)\n",
    "\n",
    "     # If still no REM events, skip this participant\n",
    "    if rem is None or rem.summary().empty:\n",
    "        wrong_amplitude_channels.append(participant)  # Log this participant\n",
    "        rem_window_results.append((participant, 0, 0, 0, 0, 0, 0, 0))\n",
    "        return 0, sf, ROC_data, LOC_data, rem_window_results\n",
    "    else:\n",
    "        # Extract the summary of REM events\n",
    "        rem_events = rem.summary()\n",
    "\n",
    "        # Iterate over each 2-second window\n",
    "        for i in range(int(num_windows)*2):\n",
    "            # Adjust the start and end times for each window\n",
    "            start_sec = i  # Start from 1 sec and then add window * i\n",
    "            end_sec = start_sec + window\n",
    "            hypno_value = hypno[i // 20]  # Get hypnogram value for the current 2-sec window\n",
    "\n",
    "            rem_in_window = rem_events[(rem_events['Peak'] >= start_sec) & (rem_events['Peak'] < end_sec)]\n",
    "            loc_max_amplitude = max(ROC_data[int(start_sec * sf):int(end_sec * sf)])\n",
    "            roc_max_amplitude = max(LOC_data[int(start_sec * sf):int(end_sec * sf)])\n",
    "            window_max_amplitude = max(loc_max_amplitude, roc_max_amplitude)\n",
    "\n",
    "            artifact_value = artefacts[i // 4]\n",
    "            if not rem_in_window.empty:\n",
    "                max_loc_abs_peak = rem_in_window['LOCAbsValPeak'].max()\n",
    "                rem_window_results.append((participant, start_sec, end_sec, artifact_value,  hypno_value, True, window_max_amplitude, max_loc_abs_peak))\n",
    "            else:\n",
    "                max_loc_abs_peak = 0\n",
    "                rem_window_results.append((participant, start_sec, end_sec, artifact_value, hypno_value, False, window_max_amplitude, max_loc_abs_peak))\n",
    "\n",
    "        return rem, sf, ROC_data, LOC_data, rem_window_results\n",
    "\n",
    "# Define the function to save the data\n",
    "def save_to_txt(file_path, data):\n",
    "    # Convert list of tuples to a NumPy array for saving\n",
    "    data_array = np.array(data, dtype=object)\n",
    "\n",
    "    # Save the array to a text file\n",
    "    np.savetxt(file_path, data_array, fmt='%s', delimiter=',')\n",
    "\n",
    "def save_to_txt(data, file_path):\n",
    "    # Convert list of tuples to a NumPy array for saving\n",
    "    data_array = np.array(data, dtype=object)\n",
    "\n",
    "    # Check if the file_path is a string and if data_array is correctly formatted\n",
    "    if isinstance(file_path, str) and data_array.ndim == 2:\n",
    "        # Save the array to a text file\n",
    "        np.savetxt(file_path, data_array, fmt='%s', delimiter=',')\n",
    "    else:\n",
    "        print(\"Error: file_path must be a string and data must be a 2D array\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for participant in participants:\n",
    "\n",
    "    edf_path = fr'D:\\EDF\\{participant}.edf'\n",
    "    hypnogram_path = fr'D:\\hypno\\{participant}.hyp.txt'\n",
    "    artefact_path = fr'D:\\automatic_artefacts\\{participant}.art.txt'\n",
    "    print(\"######################Current participant: \", participant, \"########################\")\n",
    "\n",
    "    #Load the participants EDF file\n",
    "    raw_data = mne.io.read_raw_edf(edf_path, preload=True, include=['REOG', 'LEOG', 'T1/A1A2', 'T2/A1A2','eog1', 'eog2', 'eog1-a2', 'eog2-a1', 'LOC - ROC', 'EOG1+'])\n",
    "\n",
    "    # Load participant's hypnogram\n",
    "    # Load the hypnogram file (had to rename it because of the \".\" and the \" \")\n",
    "    hypno = np.loadtxt(hypnogram_path)\n",
    "\n",
    "    # Calculate the duration of the raw data in seconds\n",
    "    raw_data_duration_sec = raw_data.times[-1]\n",
    "\n",
    "    # Calculate the expected number of hypnogram data points\n",
    "    expected_hypno_length = math.ceil(raw_data_duration_sec / 20)\n",
    "\n",
    "    # Compare the actual hypnogram length with the expected length\n",
    "    if len(hypno) == expected_hypno_length:\n",
    "        print(\"The hypnogram file matches the length of the raw_data file.\")\n",
    "    else:\n",
    "        print(f\"Mismatch in lengths. Expected {expected_hypno_length} data points in the hypnogram, found {len(hypno)}.\")\n",
    "\n",
    "    # Check if there is a mismatch in lengths\n",
    "    if len(hypno) < expected_hypno_length:\n",
    "        missing_length = expected_hypno_length - len(hypno)\n",
    "        print(f\"Mismatch in lengths. Expected {expected_hypno_length} data points in the artefact file, found {len(hypno)}. Appending {missing_length} missing rows.\")\n",
    "\n",
    "        # Create an array of ones for the missing data points\n",
    "        missing_data = np.ones(missing_length)\n",
    "\n",
    "        # Append the missing data to the artefacts array\n",
    "        hypno = np.concatenate((hypno, missing_data))\n",
    "    else:\n",
    "        print(\"The hypnogram file matches the length of the raw_data file.\")\n",
    "\n",
    "    \n",
    "    # Calculate the expected number of hypnogram data points\n",
    "    expected_artefact_length = math.ceil(raw_data_duration_sec / 4)\n",
    "    # Try to load participant's artefact data\n",
    "    try:\n",
    "        artefacts = np.loadtxt(artefact_path)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"No artefact file found for {participant}. Using an array of ones.\")\n",
    "        # Calculate the expected number of artefact data points\n",
    "        artefacts = np.ones(expected_artefact_length)  # Create an array of ones\n",
    "\n",
    "    # Compare the actual hypnogram length with the expected length\n",
    "    if len(artefacts) == expected_artefact_length:\n",
    "        print(\"The artefact file matches the length of the raw_data file.\")\n",
    "    else:\n",
    "        print(f\"Mismatch in lengths. Expected {expected_artefact_length} data points in the artefact file, found {len(artefacts)}.\")\n",
    "\n",
    "    # Check if there is a mismatch in lengths\n",
    "    if len(artefacts) < expected_artefact_length:\n",
    "        missing_length = expected_artefact_length - len(artefacts)\n",
    "        print(f\"Mismatch in lengths. Expected {expected_artefact_length} data points in the artefact file, found {len(artefacts)}. Appending {missing_length} missing rows.\")\n",
    "\n",
    "        # Create an array of ones for the missing data points\n",
    "        missing_data = np.ones(missing_length)\n",
    "\n",
    "        # Append the missing data to the artefacts array\n",
    "        artefacts = np.concatenate((artefacts, missing_data))\n",
    "    else:\n",
    "        print(\"The artefact file matches the length of the raw_data file.\")\n",
    "\n",
    "\n",
    "\n",
    "    channel_names = raw_data.info['ch_names']\n",
    "\n",
    "    # Define potential ROC-LOC channel pairs based on common configurations in your dataset\n",
    "    channel_pairs = [\n",
    "        ('REOG', 'LEOG'),\n",
    "        ('T1/A1A2', 'T2/A1A2'),\n",
    "        ('eog1-a2', 'eog2-a1'),\n",
    "        ('eog1', 'eog2'),\n",
    "        #('ROC - A1, LOC - A2')\n",
    "        ]\n",
    "\n",
    "    detected = False\n",
    "\n",
    "    # Check if EOG1+ is in channel names and proceed with the specific logic for this case\n",
    "    print(channel_names)\n",
    "    if 'EOG1+' or 'LOC - ROC' in channel_names:\n",
    "        ch_name = raw_data.info['ch_names'][0]\n",
    "        # Logic for EOG1+ case\n",
    "        eog_plus_data = raw_data.pick_channels([ch_name]).get_data()\n",
    "        eog_neg_data = -1 * eog_plus_data\n",
    "        ch_info = mne.create_info(ch_names=['EOG-'], sfreq=raw_data.info['sfreq'], ch_types=['eog'])\n",
    "        eog_neg_raw = mne.io.RawArray(eog_neg_data, ch_info)\n",
    "        raw_data.add_channels([eog_neg_raw], force_update_info=True)\n",
    "        # Define custom scaling for EOG channels\n",
    "        # scalings = {'eog': 20e-6}  # This is an example scaling factor in Volts\n",
    "        # Create a copy of the raw data\n",
    "        raw_data_filtered = raw_data.copy()\n",
    "        # Apply a bandpass filter between 0.3 and 10 Hz to the data (focus just EOG+/-)\n",
    "        raw_data_filtered.filter(l_freq=0.3, h_freq=10, picks=[ch_name, 'EOG-'])\n",
    "        # Call the detect_rems function for both unfiltered and filtered data\n",
    "        # rem_unfilt_eog, sf_unfilt, roc_unfilt_eog, loc_unfilt_eog, rem_window_results_unfilt_eog = detect_rems(raw_data, 'EOG1+', 'EOG-', hypno, artefacts)\n",
    "        rem_filt_eog, sf_filt, roc_filt_eog, loc_filt_eog, rem_window_results_filt_eog = detect_rems(raw_data_filtered, ch_name, 'EOG-', hypno, artefacts)\n",
    "        detected = True\n",
    "    else:\n",
    "        # Check for any of the other EOG channel pairs\n",
    "        for roc, loc in channel_pairs:\n",
    "            if roc in channel_names and loc in channel_names:\n",
    "                print(roc + loc)\n",
    "                # Define custom scaling for EOG channels\n",
    "                # scalings = {'eog': 20e-6}  # This is an example scaling factor in Volts\n",
    "                # Create a copy of the raw data\n",
    "                raw_data_filtered = raw_data.copy()\n",
    "                # Apply a bandpass filter between 0.3 and 10 Hz to the data (focus just EOG+/-)\n",
    "                # raw_data_filtered.filter(l_freq=0.3, h_freq=10, picks=['EOG+','ROC-M1','LOC-M2','EOG-'])\n",
    "                raw_data_filtered.filter(l_freq=0.3, h_freq=10, picks=[roc,loc])\n",
    "                # Call the detect_rems function for both unfiltered and filtered data\n",
    "                #####rem_unfilt_eog, sf_unfilt, roc_unfilt_eog, loc_unfilt_eog, rem_window_results_unfilt_eog = detect_rems(raw_data, roc, loc, hypno, artefacts)\n",
    "                rem_filt_eog, sf_filt, roc_filt_eog, loc_filt_eog, rem_window_results_filt_eog = detect_rems(raw_data_filtered, roc, loc, hypno, artefacts)\n",
    "                # ROC-LOC pair found, proceed with REM detection using these channels\n",
    "                detected = True\n",
    "                #break  # Exit the loop once a matching pair is found and processed\n",
    "\n",
    "    if not detected:\n",
    "        print(\"Required EOG channels not found in the dataset.\")\n",
    "\n",
    "\n",
    "\n",
    "    # Append the results to the all_results lists\n",
    "    # all_results_unfilt.extend(rem_window_results_unfilt_eog)\n",
    "    all_results_filt.extend(rem_window_results_filt_eog)\n",
    "\n",
    "# Convert lists to NumPy arrays for efficient storage (if necessary)\n",
    "# all_results_unfilt_array = np.array(all_results_unfilt)\n",
    "all_results_filt_array = np.array(all_results_filt)\n",
    "output_path_filt =  r'C:\\Users\\Webpredict\\Documents\\MSCthesis\\all_results_filt.txt'\n",
    "save_to_txt(all_results_filt,output_path_filt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
